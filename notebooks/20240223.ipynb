{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/ppy3x1qd5kl5tbxm42zdt0nh0000gp/T/ipykernel_20663/4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "# train model on data\n",
    "# test model\n",
    "# run feature importance to understand categorisation?\n",
    "# run on different dataset (?) - with categories etc.\n",
    "# use LDA to see if we can identify what types of features users are after?\n",
    "# use sentiment analysis to understand if characteristics are as expected of the different categories\n",
    "# reduce dimensions and visualise the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../papers/Kano-Model-Classification/datasets/Stanik_dataset/DATASET_not_downsampled.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6070, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review', 'kano_labels', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>kano_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No good. It will let me make them but I can't ...</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Can not edit PDF :-( I just wanna note somethi...</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not good Why i cannot clear chat history. Come...</td>\n",
       "      <td>P</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wish someone warned me before . . . . . . no s...</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just ok For God's sake we need a new icon and ...</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review kano_labels  \\\n",
       "0           0  No good. It will let me make them but I can't ...           B   \n",
       "1           1  Can not edit PDF :-( I just wanna note somethi...           B   \n",
       "2           2  Not good Why i cannot clear chat history. Come...           P   \n",
       "3           3  Wish someone warned me before . . . . . . no s...           B   \n",
       "4           4  Just ok For God's sake we need a new icon and ...           B   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       0  \n",
       "2       3  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "Name: kano_labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numeric labels associated with only 1 kano_labels\n",
    "df.groupby(\"labels\")[\"kano_labels\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kano_labels\n",
       "B    1440\n",
       "D     648\n",
       "I    2452\n",
       "P    1530\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"kano_labels\").size()\n",
    "\n",
    "# data doesn't seem imbalanced enough for undersampling\n",
    "# B = Basic, D= Delighter, I = Irrelevant, P = Performance\n",
    "# Naive classifier classifying everything as Irrelevant would achieve 40% acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature creation\n",
    "# options are: one hot encoding (binary), bag of words (count), tfidf (word frequency compared to other docs),  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the embedding method: https://medium.com/@juanc.olamendy/unlocking-the-power-of-text-classification-with-embeddings-7bcbb5912790\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def get_embedding(review):\n",
    "    # TODO: meaning of the diff bits of this tokenizer\n",
    "    inputs = tokenizer(review, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # TODO: Why mean of last layer hidden states as sentence embedding\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def get_centroid(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def get_nearest_label(embedding, centroid_dict):\n",
    "    nearest_label = \"\"\n",
    "    nearest_label_distance = float(\"inf\")\n",
    "    for label, centroid in centroid_dict.items():\n",
    "        label_distance = np.linalg.norm(embedding - centroid)\n",
    "        if label_distance < nearest_label_distance:\n",
    "            nearest_label = label\n",
    "            nearest_label_distance = label_distance\n",
    "\n",
    "    return pd.Series([nearest_label, nearest_label_distance])\n",
    "\n",
    "def calculate_centroids(df):\n",
    "    # Transform the data\n",
    "    df[\"embedding\"] = df[\"review\"].apply(get_embedding)\n",
    "\n",
    "    # Get embeddings for all sentences of each type\n",
    "    label_embeddings = df.groupby(\"kano_labels\")[\"embedding\"].apply(list).reset_index().rename(columns={\"embedding\": \"embeddings\"})\n",
    "\n",
    "    # Get centroids for each label\n",
    "    label_embeddings[\"centroid\"] = label_embeddings[\"embeddings\"].apply(get_centroid)\n",
    "\n",
    "    return label_embeddings\n",
    "\n",
    "\n",
    "def classify_reviews(df, label_embeddings):\n",
    "    \n",
    "    centroid_dict = {row[\"kano_labels\"]: row[\"centroid\"][0] for row in label_embeddings.to_dict(orient=\"records\")}\n",
    "    \n",
    "    # Transform the data\n",
    "    df[\"embedding\"] = df[\"review\"].apply(get_embedding)\n",
    "\n",
    "    # Label data\n",
    "    df[[\"nearest_label\", \"nearest_label_distance\"]] = df[\"embedding\"].apply(lambda x: get_nearest_label(x, centroid_dict))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "classify_reviews() missing 2 required positional arguments: 'label_embeddings' and 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m centroid_df \u001b[38;5;241m=\u001b[39m calculate_centroids(train_data)\n\u001b[1;32m     14\u001b[0m centroid_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkano_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentroid\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/centroids_full.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m test_output \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test_output[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkano_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest_label\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest_label_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/test_labelled.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: classify_reviews() missing 2 required positional arguments: 'label_embeddings' and 'df'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"../papers/Kano-Model-Classification/datasets/Stanik_dataset/DATASET_not_downsampled.xlsx\", index_col=0)\n",
    "\n",
    "# data.head()\n",
    "\n",
    "X = data[[c for c in data.columns if c!= \"kano_labels\"]]\n",
    "y = data[\"kano_labels\"]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "train_data = train_X.assign(kano_labels=train_y.values) \n",
    "test_data = test_X.assign(kano_labels=test_y.values) \n",
    "\n",
    "centroid_df = calculate_centroids(train_data)\n",
    "centroid_df[[\"kano_labels\", \"centroid\"]].to_json(\"../data/centroids_full.json\")\n",
    "\n",
    "test_output = classify_reviews(test_data, centroid_df)\n",
    "test_output[[\"review\", \"kano_labels\", \"nearest_label\", \"nearest_label_distance\"]].to_csv(\"../data/test_labelled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"../data/train.csv\")\n",
    "test_data.to_csv(\"../data/test.csv\")\n",
    "test_output = classify_reviews(test_data, centroid_df[[\"kano_labels\", \"centroid\"]])\n",
    "test_output[[\"review\", \"kano_labels\", \"nearest_label\", \"nearest_label_distance\"]].to_csv(\"../data/test_labelled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814936847885777\n"
     ]
    }
   ],
   "source": [
    "# check accuracy, precision, recall, f1\n",
    "\n",
    "recall_score = metrics.recall_score(test_data[\"kano_labels\"], test_output[\"nearest_label\"], average=\"weighted\")\n",
    "print(recall_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78472222 0.69587629 0.71195652 0.52941176]\n"
     ]
    }
   ],
   "source": [
    "# check accuracy, precision, recall, f1\n",
    "\n",
    "recall_score = metrics.recall_score(test_data[\"kano_labels\"], test_output[\"nearest_label\"], average=None, labels=[\"B\", \"D\", \"I\", \"P\"])\n",
    "print(recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76523702 0.35064935 0.87043189 0.62148338]\n"
     ]
    }
   ],
   "source": [
    "# check accuracy, precision, recall, f1\n",
    "\n",
    "precision_score = metrics.precision_score(test_data[\"kano_labels\"], test_output[\"nearest_label\"], average=None, labels=[\"B\", \"D\", \"I\", \"P\"])\n",
    "print(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7273515157176651\n"
     ]
    }
   ],
   "source": [
    "# check accuracy, precision, recall, f1\n",
    "\n",
    "precision_score = metrics.precision_score(test_data[\"kano_labels\"], test_output[\"nearest_label\"], average=\"weighted\")\n",
    "print(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Precision / recall by label\n",
    "# What does each category get misclassified for - can we investigate and understand?\n",
    "# TFIDF + log regression approach + feature importance for explainability\n",
    "# Look at how far apart the centroids are + cluster density / descriptive stats\n",
    "# Sentiment analysis to see if there are significant differences in this across different categories?\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0a5e7e1c1a45649b1e5fbe8eb8a6ccaab5323d673643f0ec2563c9321e38f10"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('capstone': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
